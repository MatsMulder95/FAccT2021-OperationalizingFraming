{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "<hr>\n",
    "\n",
    "### Pseudo-code walk-through\n",
    "To provide more insight into the actual diversification algorithm, this jupyter notebook was set up. However, the actual algorithm used for the study highly depends on the Blendle enrichment proces and datastructure. Since this environment can not be shared publicly, sharing the actual code will not be benefitial. Therefore, it was chosen to create a pseudo-code walk-through of the algorith.\n",
    "\n",
    "### Content\n",
    "1. [Enrichments](#Step-1:-Enrichment)\n",
    "2. [Diversity Function](#Diversity-Functions)\n",
    "3. [Re-ranking](#Re-ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichment\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x = number of assumed introduction paragraphs of article\n",
    "y = number of assumed concluding paragraphs of article\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem Definition\n",
    "The pipeline below describes the enrichment process related to the problem defintion framing function.\n",
    "* It is assumed that a trained topic-model is available.\n",
    "* The methods returns the topic distribution over the x introduction paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "enrichmentPipeline = Pipeline('cleaner', 'tokenizer', 'stemmer', 'topic-model')\n",
    "\n",
    "For article i in dataset:\n",
    "   For first x paragraphs p in i:\n",
    "       enrichmentPipeline.enrich(p)\n",
    "       \n",
    "   return topic-distribution over x introduction paragraphs\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Causal Attribution\n",
    "The pipeline below describes the enrichment process related to the causal attribution framing function.\n",
    "* The method uses both the Google Translate API (could be neglected if articles are in supported languages) and IBM Watson API.\n",
    "* The method returns the IBM watson category hierarchy for each body paragraph (https://cloud.ibm.com/apidocs/natural-language-understanding#categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "enrichmentPipeline = Pipeline('googleTranslate', 'ibmWatson('categories')')\n",
    "\n",
    "For article i in dataset:\n",
    "   bodyParagraphs[] = i.paragraphs - x - y\n",
    "   For paragraph p in bodyParagraph:\n",
    "       enrichmentPipeline.enrich(p)\n",
    "       \n",
    "   return ibm_categories_hierarchy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Moral Evaluation\n",
    "The pipeline below describes the enrichment process related to moral evaluation framing function. \n",
    "* The method uses both the Google Translate API (could be neglected if articles are in supported languages) and IBM Watson API.\n",
    "* The method returns the IBM sentiment score for each body paragraph (https://cloud.ibm.com/apidocs/natural-language-understanding#sentiment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "enrichmentPipeline = Pipeline('googleTranslate', 'ibmWatson('sentiment')')\n",
    "\n",
    "For article i in dataset:\n",
    "   bodyParagraphs[] = i.paragraphs - x - y\n",
    "   For paragraph p in bodyParagraph:\n",
    "       enrichmentPipeline.enrich(p)\n",
    "       \n",
    "   return ibm_sentiment_score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Treatment Recommendations\n",
    "The pipeline below describes the enrichment process related to treatment recommendation framing function.\n",
    "* The method checks for each sentence in the concluding paragraphs if it contains a treatment recommendation\n",
    "* If the sentence includes a treatment recommendation, the sentence is send to IBM Watson (categories)\n",
    "* The methods returns the category hierarchy of the sentences with a treatment recommendation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "keywords = ['suggest', 'recommend', 'hopefully', 'go for', 'request', 'it would be nice', 'adding', 'should come with', 'should be able', 'could come with', 'i need', 'we need', 'needs', 'needs to', 'need to', 'would like to', 'would','love to', 'i wish', 'i hope', 'i want', 'hopefully', 'if only', 'would be better if', 'would that', 'i can has','do want','should', 'there should be', 'i cannot', 'ability to','ability of']\n",
    "\n",
    "modal_words = ['can', 'would', 'could', 'must', 'may', 'shall', 'might', 'should', 'will', 'ought to']\n",
    "\n",
    "function checkSentence(sentence):\n",
    "    for word w in sentence:\n",
    "        if w in keywords:\n",
    "            return true\n",
    "        if (s[w].pos in ['NN','NNS','NNP','NNPS','PRP','PDT','DT'] && ] s[w+1].pos in ['VB','VBP']):\n",
    "            return true\n",
    "        if (s[w].lemma in modal_words && s[w+1].pos == 'VB'):\n",
    "            return true\n",
    "            \n",
    "enrichmentPipeline_1 = Pipeline('googleTranslate', 'coreNLP('tokenize','ssplit','pos','depparse','parse','lemma')')\n",
    "enrichmentPipeline_2 = Pipeline('ibmWatson('categories)')\n",
    "\n",
    "    \n",
    "For article i in Datasaet:\n",
    "    For last y paragraphs p in i:\n",
    "        enrichment = enrichmentPipeline_1.enrich(p)\n",
    "            For sentence s in enrichment:\n",
    "                if checkSentence(s):\n",
    "                    enrichmentPipeline_2.enrich(p)\n",
    "    return ibm_categories_hierarchy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity Functions\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition\n",
    "The following pseudo-code calculates the diversity score between two articles related to the problem definition framing function.\n",
    "* The kullback leibler divergence between two topic distribution was used (assuming all probabililties are > 0)\n",
    "* The method returns the kullback leibler divergence between all pairs of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "For article i in dataset:\n",
    "    For article j in [dataset - i]:\n",
    "       return kl_Divergence(i, j)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Atrribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pseudo-code calculates the diversity score between two articles related to the causal attribution framing function.\n",
    "* The weighted jaccard index is calculated between the category arrays of all paragraphs combinations of two articles\n",
    "* Two setups were used: equal contribution of each hierarchy level or increasing contribution for increasing hierarchy levels\n",
    "* The method returns the mean jaccard index of all paragraph combinations of two articles (negative because jaccard returns similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "For article i in dataset:\n",
    "    For article j in [dataset - i]:\n",
    "       For all paragraph combinations s,t of i and j:\n",
    "           jaccard[s,t] = weighted_jaccard_index(s.categories, t.categories)\n",
    "    return -1 * mean(jaccard)\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral Evaluation\n",
    "The following pseudo-code calculates the diversity score between two articles related to the moral evaluation framing function.\n",
    "* The score of a combination of two paragaphs is calculated by the jaccard index of the parahraph combination times the absolute difference in ibm sentiment score (thus more overlapping paragrahs have a higher contribution)\n",
    "* The method returns the mean sentiment score of each paragraph combination of two articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "For article i in dataset:\n",
    "    For article j in [dataset - i]:\n",
    "       For all paragraph combinations s,t of i and j:\n",
    "           sentiment[s,t] = abs(sentiment(s) - sentiment(t)) * jaccard(s,t)\n",
    "    return mean(sentiment)\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pseudo-code calculates the diversity score between two articles related to the treatment recommendation framing function.\n",
    "* The weighted jaccard index is calculated between the category arrays of combinations of sentences in which a treatment recommendation was found\n",
    "* Two setups were used: equal contribution of each hierarchy level or increasing contribution for increasing hierarchy levels\n",
    "* The method returns the mean jaccard index over all sentence combinations (negative because jaccard returns similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "For article i in dataset:\n",
    "    For article j in [dataset - i]:\n",
    "       For all combinations of sentences with a treatment recommendation s,t of i and j:\n",
    "           jaccard[s,t] = weighted_jaccard_index(s.categories, t.categories)\n",
    "    return -1 * mean(jaccard)\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-ranking\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "weighfactors = [w1, w2, w3, w4]\n",
    "d_1[i, j] = problem definition diversity score article i, j\n",
    "d_2[i, j] = causal attribution diversity score article i, j\n",
    "d_3[i, j] = moral evaluation diversity score article i, j\n",
    "d_4[i, j] = treatment recommendation diversity score article i, j\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Diversity Scores + fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, the diversity matrices related to each framing function are normalized\n",
    "* Afterwards, missing values (if for example no data was available for a framing function) are replaced by the mean of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "min_max_normalize(d_1, d_2, d_3, d_4)\n",
    "\n",
    "For article i in dataset:\n",
    "   For article j in [dataset - i]:\n",
    "       if d_x[i, j] == 0:\n",
    "           d_x[i, j] = mean(d_x)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Total Diversity Score\n",
    "The method below calculates the total diversity score between two articles\n",
    "* The sore is a simple weighted sum of the diversity scores related to each framing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "For article i in dataset:\n",
    "    For article j in [dataset - i]:\n",
    "       diversity[i,j] = (w1 * d_1[i,j]) + (w2 * d_2[i,j]) + (w3 * d_3[i,j]) + (w4 * d_4[i,j])\n",
    "    \n",
    "    return diversity\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Relevance Score\n",
    "The method below calculates the relevance score between two articles\n",
    "* The sore is implemented as a TF-IDF score between the content of both articles\n",
    "* In the original method the sklearn TfidfVectorizer was used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "For article i in dataset:\n",
    "    For article j in [dataset - i]:\n",
    "       relevance[i,j] = TF_IDF(i, j)\n",
    "       \n",
    "    return min_max_normalize(relevance)\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMR\n",
    "The method describes the MMR function\n",
    "* The method outputs a list of recommendations of a certain size\n",
    "* The variable λ includes the threshold between diversity and relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "function getRecommendations(original_article, size, λ):\n",
    "    article_choices = dataset = original_article\n",
    "    output = []\n",
    "    While output.length < size:\n",
    "        For article i in article_choices:\n",
    "            score[i] = (relevance[original_article, i] * λ) - ((1-λ) * diversity[original_article, i])\n",
    "        recommendation = index(max(score))\n",
    "        output.append(recommendation)\n",
    "        article_choices = article_choices - recommendation\n",
    "\n",
    "``` "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}